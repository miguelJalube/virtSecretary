version: '3.8'

services:
  chatbot:
    container_name: katIA
    build: .
    ports:
      - '$PORT:$PORT'
    env_file:
      - .env
    volumes:
      - .:/app
    environment:
      LLM: $LLM                             # Language model to use
      LLM_SERVER: $LLM_SERVER               # Endpoint URL for the llm service
      LLM_PORT : $LLM_PORT                  # Port for the the llm service
      PORT: $PORT                           # Port for the frontend
    extra_hosts:
      - "$LLM_SERVER:host-gateway"          # ONLY if running ollama locally